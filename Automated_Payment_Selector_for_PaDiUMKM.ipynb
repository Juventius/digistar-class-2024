{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "64e06451-388e-4768-9a61-682b2fd9047f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      user_id transaction_id                    items  payment_amount  \\\n",
      "0     user_54        trans_0                 [payung]       839023.28   \n",
      "1     user_82        trans_1          [pulpen, snack]       115433.21   \n",
      "2     user_94        trans_2  [snack, payung, pulpen]       472886.31   \n",
      "3     user_98        trans_3      [tas, snack, jaket]       974511.98   \n",
      "4     user_33        trans_4                 [pulpen]       426191.61   \n",
      "...       ...            ...                      ...             ...   \n",
      "9995   user_2     trans_9995                 [pulpen]       229704.51   \n",
      "9996  user_17     trans_9996                 [pulpen]       427062.18   \n",
      "9997  user_67     trans_9997          [payung, jaket]       517338.51   \n",
      "9998  user_94     trans_9998    [jaket, buku, payung]       607032.80   \n",
      "9999   user_8     trans_9999              [air galon]       548051.20   \n",
      "\n",
      "                           date payment_method  \n",
      "0    2024-08-21 22:03:12.598092         VA BTN  \n",
      "1    2023-12-21 22:03:12.598092         VA BRI  \n",
      "2    2023-10-05 22:03:12.598092         VA BRI  \n",
      "3    2024-06-04 22:03:12.598092         VA BTN  \n",
      "4    2024-03-16 22:03:12.598092         VA BNI  \n",
      "...                         ...            ...  \n",
      "9995 2024-05-29 22:03:12.649726         VA BSI  \n",
      "9996 2023-10-28 22:03:12.649726         VA BNI  \n",
      "9997 2023-11-12 22:03:12.649726         VA BTN  \n",
      "9998 2024-06-07 22:03:12.649726         VA BRI  \n",
      "9999 2024-01-25 22:03:12.649726         VA BNI  \n",
      "\n",
      "[10000 rows x 6 columns]\n",
      "Episode: 0, Epsilon: 0.9995\n",
      "Episode: 100, Epsilon: 0.9507\n",
      "Episode: 200, Epsilon: 0.9044\n",
      "Episode: 300, Epsilon: 0.8602\n",
      "Episode: 400, Epsilon: 0.8183\n",
      "Episode: 500, Epsilon: 0.7784\n",
      "Episode: 600, Epsilon: 0.7404\n",
      "Episode: 700, Epsilon: 0.7043\n",
      "Episode: 800, Epsilon: 0.6699\n",
      "Episode: 900, Epsilon: 0.6372\n",
      "Episode: 1000, Epsilon: 0.6062\n",
      "Episode: 1100, Epsilon: 0.5766\n",
      "Episode: 1200, Epsilon: 0.5485\n",
      "Episode: 1300, Epsilon: 0.5217\n",
      "Episode: 1400, Epsilon: 0.4963\n",
      "Episode: 1500, Epsilon: 0.4720\n",
      "Episode: 1600, Epsilon: 0.4490\n",
      "Episode: 1700, Epsilon: 0.4271\n",
      "Episode: 1800, Epsilon: 0.4063\n",
      "Episode: 1900, Epsilon: 0.3865\n",
      "Episode: 2000, Epsilon: 0.3676\n",
      "Episode: 2100, Epsilon: 0.3497\n",
      "Episode: 2200, Epsilon: 0.3326\n",
      "Episode: 2300, Epsilon: 0.3164\n",
      "Episode: 2400, Epsilon: 0.3010\n",
      "Episode: 2500, Epsilon: 0.2863\n",
      "Episode: 2600, Epsilon: 0.2723\n",
      "Episode: 2700, Epsilon: 0.2590\n",
      "Episode: 2800, Epsilon: 0.2464\n",
      "Episode: 2900, Epsilon: 0.2344\n",
      "Episode: 3000, Epsilon: 0.2229\n",
      "Episode: 3100, Epsilon: 0.2121\n",
      "Episode: 3200, Epsilon: 0.2017\n",
      "Episode: 3300, Epsilon: 0.1919\n",
      "Episode: 3400, Epsilon: 0.1825\n",
      "Episode: 3500, Epsilon: 0.1736\n",
      "Episode: 3600, Epsilon: 0.1651\n",
      "Episode: 3700, Epsilon: 0.1571\n",
      "Episode: 3800, Epsilon: 0.1494\n",
      "Episode: 3900, Epsilon: 0.1421\n",
      "Episode: 4000, Epsilon: 0.1352\n",
      "Episode: 4100, Epsilon: 0.1286\n",
      "Episode: 4200, Epsilon: 0.1223\n",
      "Episode: 4300, Epsilon: 0.1164\n",
      "Episode: 4400, Epsilon: 0.1107\n",
      "Episode: 4500, Epsilon: 0.1053\n",
      "Episode: 4600, Epsilon: 0.1002\n",
      "Episode: 4700, Epsilon: 0.0953\n",
      "Episode: 4800, Epsilon: 0.0906\n",
      "Episode: 4900, Epsilon: 0.0862\n",
      "Episode: 5000, Epsilon: 0.0820\n",
      "Episode: 5100, Epsilon: 0.0780\n",
      "Episode: 5200, Epsilon: 0.0742\n",
      "Episode: 5300, Epsilon: 0.0706\n",
      "Episode: 5400, Epsilon: 0.0671\n",
      "Episode: 5500, Epsilon: 0.0639\n",
      "Episode: 5600, Epsilon: 0.0607\n",
      "Episode: 5700, Epsilon: 0.0578\n",
      "Episode: 5800, Epsilon: 0.0550\n",
      "Episode: 5900, Epsilon: 0.0523\n",
      "Episode: 6000, Epsilon: 0.0497\n",
      "Episode: 6100, Epsilon: 0.0473\n",
      "Episode: 6200, Epsilon: 0.0450\n",
      "Episode: 6300, Epsilon: 0.0428\n",
      "Episode: 6400, Epsilon: 0.0407\n",
      "Episode: 6500, Epsilon: 0.0387\n",
      "Episode: 6600, Epsilon: 0.0368\n",
      "Episode: 6700, Epsilon: 0.0350\n",
      "Episode: 6800, Epsilon: 0.0333\n",
      "Episode: 6900, Epsilon: 0.0317\n",
      "Episode: 7000, Epsilon: 0.0302\n",
      "Episode: 7100, Epsilon: 0.0287\n",
      "Episode: 7200, Epsilon: 0.0273\n",
      "Episode: 7300, Epsilon: 0.0260\n",
      "Episode: 7400, Epsilon: 0.0247\n",
      "Episode: 7500, Epsilon: 0.0235\n",
      "Episode: 7600, Epsilon: 0.0223\n",
      "Episode: 7700, Epsilon: 0.0212\n",
      "Episode: 7800, Epsilon: 0.0202\n",
      "Episode: 7900, Epsilon: 0.0192\n",
      "Episode: 8000, Epsilon: 0.0183\n",
      "Episode: 8100, Epsilon: 0.0174\n",
      "Episode: 8200, Epsilon: 0.0165\n",
      "Episode: 8300, Epsilon: 0.0157\n",
      "Episode: 8400, Epsilon: 0.0150\n",
      "Episode: 8500, Epsilon: 0.0142\n",
      "Episode: 8600, Epsilon: 0.0135\n",
      "Episode: 8700, Epsilon: 0.0129\n",
      "Episode: 8800, Epsilon: 0.0123\n",
      "Episode: 8900, Epsilon: 0.0117\n",
      "Episode: 9000, Epsilon: 0.0111\n",
      "Episode: 9100, Epsilon: 0.0105\n",
      "Episode: 9200, Epsilon: 0.0100\n",
      "Episode: 9300, Epsilon: 0.0100\n",
      "Episode: 9400, Epsilon: 0.0100\n",
      "Episode: 9500, Epsilon: 0.0100\n",
      "Episode: 9600, Epsilon: 0.0100\n",
      "Episode: 9700, Epsilon: 0.0100\n",
      "Episode: 9800, Epsilon: 0.0100\n",
      "Episode: 9900, Epsilon: 0.0100\n",
      "Accuracy on test data: 0.2035\n",
      "Received new data. Learning from it...\n",
      "Episode: 0, Epsilon: 0.0100\n",
      "Episode: 100, Epsilon: 0.0100\n",
      "Episode: 200, Epsilon: 0.0100\n",
      "Episode: 300, Epsilon: 0.0100\n",
      "Episode: 400, Epsilon: 0.0100\n",
      "Episode: 500, Epsilon: 0.0100\n",
      "Episode: 600, Epsilon: 0.0100\n",
      "Episode: 700, Epsilon: 0.0100\n",
      "Episode: 800, Epsilon: 0.0100\n",
      "Episode: 900, Epsilon: 0.0100\n",
      "Accuracy on new data: 0.5850\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Press Enter to process next batch of data, or 'q' to quit:  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Received new data. Learning from it...\n",
      "Episode: 0, Epsilon: 0.0100\n",
      "Episode: 100, Epsilon: 0.0100\n",
      "Episode: 200, Epsilon: 0.0100\n",
      "Episode: 300, Epsilon: 0.0100\n",
      "Episode: 400, Epsilon: 0.0100\n",
      "Episode: 500, Epsilon: 0.0100\n",
      "Episode: 600, Epsilon: 0.0100\n",
      "Episode: 700, Epsilon: 0.0100\n",
      "Episode: 800, Epsilon: 0.0100\n",
      "Episode: 900, Epsilon: 0.0100\n",
      "Accuracy on new data: 0.6020\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Press Enter to process next batch of data, or 'q' to quit:  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Received new data. Learning from it...\n",
      "Episode: 0, Epsilon: 0.0100\n",
      "Episode: 100, Epsilon: 0.0100\n",
      "Episode: 200, Epsilon: 0.0100\n",
      "Episode: 300, Epsilon: 0.0100\n",
      "Episode: 400, Epsilon: 0.0100\n",
      "Episode: 500, Epsilon: 0.0100\n",
      "Episode: 600, Epsilon: 0.0100\n",
      "Episode: 700, Epsilon: 0.0100\n",
      "Episode: 800, Epsilon: 0.0100\n",
      "Episode: 900, Epsilon: 0.0100\n",
      "Accuracy on new data: 0.5950\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Press Enter to process next batch of data, or 'q' to quit:  q\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent saved successfully.\n",
      "Preprocessors saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "from collections import defaultdict\n",
    "\n",
    "# Generate dummy data\n",
    "def generate_dummy_data(num_rows=10000):\n",
    "    user_ids = [f\"user_{i}\" for i in range(100)]  # 100 unique users\n",
    "    items = ['buku', 'pulpen', 'air galon', 'snack', 'jaket', 'payung', 'tas']\n",
    "    payment_methods = ['VA Mandiri', 'VA BNI', 'VA BRI', 'VA BSI', 'VA BTN']\n",
    "    \n",
    "    data = []\n",
    "    for i in range(num_rows):\n",
    "        user_id = random.choice(user_ids)\n",
    "        transaction_id = f\"trans_{i}\"\n",
    "        num_items = random.randint(1, 3)\n",
    "        transaction_items = random.sample(items, num_items)\n",
    "        payment_amount = round(random.uniform(100000, 1000000), 2)\n",
    "        date = datetime.now() - timedelta(days=random.randint(0, 365))\n",
    "        payment_method = random.choice(payment_methods)\n",
    "        \n",
    "        data.append([user_id, transaction_id, transaction_items, payment_amount, date, payment_method])\n",
    "    \n",
    "    df = pd.DataFrame(data, columns=['user_id', 'transaction_id', 'items', 'payment_amount', 'date', 'payment_method'])\n",
    "    return df\n",
    "\n",
    "# Q-learning agent\n",
    "class QLearningAgent:\n",
    "    def __init__(self, state_size, action_size, learning_rate=0.1, discount_factor=0.95, epsilon=1.0, epsilon_min=0.01, epsilon_decay=0.9995):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.discount_factor = discount_factor\n",
    "        self.epsilon = epsilon\n",
    "        self.epsilon_min = epsilon_min\n",
    "        self.epsilon_decay = epsilon_decay\n",
    "        self.q_table = defaultdict(self.default_q_value)\n",
    "\n",
    "    def default_q_value(self):\n",
    "        return np.zeros(self.action_size)\n",
    "    \n",
    "    def get_action(self, state):\n",
    "        if np.random.rand() < self.epsilon:\n",
    "            return np.random.randint(self.action_size)\n",
    "        return np.argmax(self.q_table[state])\n",
    "    \n",
    "    def update_q_table(self, state, action, reward, next_state):\n",
    "        current_q = self.q_table[state][action]\n",
    "        next_max_q = np.max(self.q_table[next_state])\n",
    "        new_q = current_q + self.learning_rate * (reward + self.discount_factor * next_max_q - current_q)\n",
    "        self.q_table[state][action] = new_q\n",
    "    \n",
    "    def decay_epsilon(self):\n",
    "        self.epsilon = max(self.epsilon_min, self.epsilon * self.epsilon_decay)\n",
    "\n",
    "    def learn_from_new_data(self, new_data, num_episodes=1000, batch_size=32):\n",
    "        for episode in range(num_episodes):\n",
    "            batch = new_data.sample(n=batch_size, replace=True)\n",
    "            for _, row in batch.iterrows():\n",
    "                state = get_state(row)\n",
    "                action = self.get_action(state)\n",
    "                next_state = get_state(new_data.iloc[np.random.randint(len(new_data))])\n",
    "                reward = 1 if action == row['payment_method_encoded'] else -1\n",
    "                self.update_q_table(state, action, reward, next_state)\n",
    "            \n",
    "            self.decay_epsilon()\n",
    "            \n",
    "            if episode % 100 == 0:\n",
    "                print(f\"Episode: {episode}, Epsilon: {self.epsilon:.4f}\")\n",
    "\n",
    "# Define state\n",
    "def get_state(row):\n",
    "    return (row['user_id_encoded'], \n",
    "            tuple(row['items_encoded']), \n",
    "            row['payment_amount'],\n",
    "            row['day_of_week'],\n",
    "            row['month'])\n",
    "\n",
    "# Preprocess data\n",
    "def preprocess_data(df):\n",
    "    le_user = LabelEncoder()\n",
    "    le_item = LabelEncoder()\n",
    "    le_method = LabelEncoder()\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    df['user_id_encoded'] = le_user.fit_transform(df['user_id'])\n",
    "    df['items_encoded'] = df['items'].apply(lambda x: le_item.fit_transform(x))\n",
    "    df['payment_method_encoded'] = le_method.fit_transform(df['payment_method'])\n",
    "\n",
    "    df['day_of_week'] = df['date'].dt.dayofweek\n",
    "    df['month'] = df['date'].dt.month\n",
    "\n",
    "    df[['payment_amount', 'day_of_week', 'month']] = scaler.fit_transform(df[['payment_amount', 'day_of_week', 'month']])\n",
    "\n",
    "    return df, le_user, le_item, le_method, scaler\n",
    "\n",
    "# Process new data\n",
    "def process_new_data(new_data, le_user, le_item, le_method, scaler):\n",
    "    new_data['user_id_encoded'] = le_user.transform(new_data['user_id'])\n",
    "    new_data['items_encoded'] = new_data['items'].apply(lambda x: le_item.transform([item for item in x if item in le_item.classes_]))\n",
    "    new_data['payment_method_encoded'] = le_method.transform(new_data['payment_method'])\n",
    "    new_data['day_of_week'] = new_data['date'].dt.dayofweek\n",
    "    new_data['month'] = new_data['date'].dt.month\n",
    "    new_data[['payment_amount', 'day_of_week', 'month']] = scaler.transform(new_data[['payment_amount', 'day_of_week', 'month']])\n",
    "    return new_data\n",
    "\n",
    "# Train the model\n",
    "def train_model(df, num_episodes=10000, batch_size=32):\n",
    "    agent = QLearningAgent(state_size=None, action_size=3)\n",
    "\n",
    "    for episode in range(num_episodes):\n",
    "        batch = df.sample(batch_size)\n",
    "        for _, row in batch.iterrows():\n",
    "            state = get_state(row)\n",
    "            action = agent.get_action(state)\n",
    "            next_state = get_state(df.iloc[np.random.randint(len(df))])\n",
    "            reward = 1 if action == row['payment_method_encoded'] else -1\n",
    "            agent.update_q_table(state, action, reward, next_state)\n",
    "        \n",
    "        agent.decay_epsilon()\n",
    "        \n",
    "        if episode % 100 == 0:\n",
    "            print(f\"Episode: {episode}, Epsilon: {agent.epsilon:.4f}\")\n",
    "\n",
    "    return agent\n",
    "\n",
    "# Evaluate the model\n",
    "def evaluate_model(agent, data):\n",
    "    correct_predictions = 0\n",
    "    for _, row in data.iterrows():\n",
    "        state = get_state(row)\n",
    "        action = agent.get_action(state)\n",
    "        if action == row['payment_method_encoded']:\n",
    "            correct_predictions += 1\n",
    "    \n",
    "    accuracy = correct_predictions / len(data)\n",
    "    return accuracy\n",
    "\n",
    "# Continuous learning\n",
    "def continuous_learning(agent, le_user, le_item, le_method, scaler):\n",
    "    while True:\n",
    "        # In a real scenario, this would be new data received from your system\n",
    "        new_data = generate_dummy_data(1000)\n",
    "        processed_new_data = process_new_data(new_data, le_user, le_item, le_method, scaler)\n",
    "        \n",
    "        print(\"Received new data. Learning from it...\")\n",
    "        agent.learn_from_new_data(processed_new_data)\n",
    "        \n",
    "        accuracy = evaluate_model(agent, processed_new_data)\n",
    "        print(f\"Accuracy on new data: {accuracy:.4f}\")\n",
    "        \n",
    "        user_input = input(\"Press Enter to process next batch of data, or 'q' to quit: \")\n",
    "        if user_input.lower() == 'q':\n",
    "            break\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Generate initial data\n",
    "    df = generate_dummy_data(10000)\n",
    "    print(df)\n",
    "\n",
    "    # Preprocess data\n",
    "    df, le_user, le_item, le_method, scaler = preprocess_data(df)\n",
    "\n",
    "    # Split data\n",
    "    train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Train the model\n",
    "    agent = train_model(train_df)\n",
    "\n",
    "    # Evaluate on test data\n",
    "    test_accuracy = evaluate_model(agent, test_df)\n",
    "    print(f\"Accuracy on test data: {test_accuracy:.4f}\")\n",
    "\n",
    "    # Start continuous learning\n",
    "    continuous_learning(agent, le_user, le_item, le_method, scaler)\n",
    "\n",
    "    # Save the model and preprocessors\n",
    "    try:\n",
    "        joblib.dump(agent, 'q_learning_agent.joblib')\n",
    "        print(\"Agent saved successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving agent: {e}\")\n",
    "\n",
    "    joblib.dump(le_user, 'le_user.joblib')\n",
    "    joblib.dump(le_item, 'le_item.joblib')\n",
    "    joblib.dump(le_method, 'le_method.joblib')\n",
    "    joblib.dump(scaler, 'scaler.joblib')\n",
    "    print(\"Preprocessors saved successfully.\")\n",
    "\n",
    "# Loading the model (for future use)\n",
    "def load_model():\n",
    "    agent = joblib.load('q_learning_agent.joblib')\n",
    "    le_user = joblib.load('le_user.joblib')\n",
    "    le_item = joblib.load('le_item.joblib')\n",
    "    le_method = joblib.load('le_method.joblib')\n",
    "    scaler = joblib.load('scaler.joblib')\n",
    "    return agent, le_user, le_item, le_method, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ee9cbc5c-d813-4079-9562-c0be2de2e38a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID: user_3\n",
      "Items: ['buku', 'pulpen']\n",
      "Payment smount: 100000\n",
      "Date of transaction: 2024-09-22 22:06:18.133949\n",
      "Predicted payment method: VA BNI\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juven\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Test with single user input\n",
    "def test_single_input(agent, le_user, le_item, le_method, scaler):\n",
    "    user_input = {\n",
    "        'user_id': 'user_3',\n",
    "        'items': ['buku', 'pulpen'],\n",
    "        'payment_amount': 100000,\n",
    "        'date': datetime.now()\n",
    "    }\n",
    "\n",
    "    print('User ID:', user_input['user_id'])\n",
    "    print('Items:', user_input['items'])\n",
    "    print('Payment smount:', user_input['payment_amount'])\n",
    "    print('Date of transaction:', user_input['date'])\n",
    "\n",
    "    state = process_single_record(user_input, le_user, le_item, scaler)\n",
    "    action = agent.get_action(state)\n",
    "    predicted_payment_method = le_method.inverse_transform([action])[0]\n",
    "    \n",
    "    print(f\"Predicted payment method: {predicted_payment_method}\")\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Load the model and preprocessors\n",
    "    agent, le_user, le_item, le_method, scaler = load_model()\n",
    "\n",
    "    # Test with single input\n",
    "    test_single_input(agent, le_user, le_item, le_method, scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6b5367-47a6-4df6-afdc-ca204dae7a10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
